{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Calculate document vectors (average of word vectors)\ndef average_word_vectors(words, model, num_features):\n    feature_vector = np.zeros((num_features,), dtype=\"float32\")\n    n_words = 0\n\n    for word in words:\n        if word in model.wv:\n            n_words += 1\n            feature_vector = np.add(feature_vector, model.wv[word])\n\n    if n_words > 0:\n        feature_vector = np.divide(feature_vector, n_words)\n    \n    return feature_vector\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-10-01T13:53:25.952020Z","iopub.execute_input":"2023-10-01T13:53:25.952662Z","iopub.status.idle":"2023-10-01T13:53:25.983339Z","shell.execute_reply.started":"2023-10-01T13:53:25.952620Z","shell.execute_reply":"2023-10-01T13:53:25.982614Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!pip install json","metadata":{"execution":{"iopub.status.busy":"2023-10-01T14:05:47.767413Z","iopub.execute_input":"2023-10-01T14:05:47.767830Z","iopub.status.idle":"2023-10-01T14:05:50.718177Z","shell.execute_reply.started":"2023-10-01T14:05:47.767799Z","shell.execute_reply":"2023-10-01T14:05:50.717136Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"\u001b[31mERROR: Could not find a version that satisfies the requirement json (from versions: none)\u001b[0m\u001b[31m\n\u001b[0m\u001b[31mERROR: No matching distribution found for json\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nfrom gensim.models import Word2Vec\n\n# Sample user profiles and project descriptions\nuser_profiles = [\n    {\n        'mandatory_skills': ['data', 'science', 'machine', 'learning','software engineering'],\n        'good_to_have_skills': ['statistics', 'python', 'programming'],\n        'expertise_level': 0.8,\n        'contributor_type': 'developer'  # Example contributor type\n    },\n    {\n        'mandatory_skills': ['biology', 'research', 'genetics', 'lab'],\n        'good_to_have_skills': ['microbiology', 'DNA sequencing'],\n        'expertise_level': 0.6,\n        'contributor_type': 'researcher'\n    },\n    {\n        'mandatory_skills': ['environment', 'sustainability', 'climate', 'change'],\n        'good_to_have_skills': ['renewable energy', 'carbon footprint'],\n        'expertise_level': 0.7,\n        'contributor_type': 'environmentalist'\n    },\n]\n\nproject_descriptions = [\n    {\n        'mandatory_skills': ['data', 'science', 'machine', 'learning'],\n        'good_to_have_skills': ['machine learning', 'data visualization'],\n        'expertise_level': 0.75,\n        'contributor_type': 'developer'\n    },\n    {\n        'mandatory_skills': ['genomics', 'study', 'gene', 'expression'],\n        'good_to_have_skills': ['genome sequencing', 'biological research'],\n        'expertise_level': 0.65,\n        'contributor_type': 'researcher'\n    },\n    {\n        'mandatory_skills': ['sustainable', 'solutions', 'carbon', 'offset'],\n        'good_to_have_skills': ['renewable energy', 'environmental policy'],\n        'expertise_level': 0.72,\n        'contributor_type': 'environmentalist'\n    },\n]\n\n# Train Word2Vec model\nmodel = Word2Vec([profile['mandatory_skills'] + profile['good_to_have_skills'] for profile in user_profiles + project_descriptions], vector_size=100, window=5, min_count=1, sg=0)\n\n# Function to calculate cosine similarity between two vectors\ndef cosine_similarity(vec1, vec2):\n    return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))\n\n# Threshold for considering expertise level similarity\nsimilarity_threshold = 0.3\n\n# Iterate through user profiles and project descriptions\nfor i, user_profile in enumerate(user_profiles):\n    for j, project_description in enumerate(project_descriptions):\n        # Check if the contributor types match\n        if user_profile['contributor_type'] == project_description['contributor_type']:\n            # Calculate similarity for mandatory skills\n            mandatory_skills_similarity = cosine_similarity(average_word_vectors(user_profile['mandatory_skills'], model, 100), average_word_vectors(project_description['mandatory_skills'], model, 100))\n            \n            # Calculate similarity for good-to-have skills\n            good_to_have_skills_similarity = cosine_similarity(average_word_vectors(user_profile['good_to_have_skills'], model, 100), average_word_vectors(project_description['good_to_have_skills'], model, 100))\n            \n            # Check if either of the skills similarities exceeds the threshold\n            if mandatory_skills_similarity > similarity_threshold or good_to_have_skills_similarity > similarity_threshold:\n                # Calculate similarity for expertise level (you can adjust the weight as needed)\n                expertise_level_similarity = 1 - abs(user_profile['expertise_level'] - project_description['expertise_level'])\n                \n                # Print the similarities for each aspect\n                print(f\"User Profile {i+1} vs. Project {j+1}:\")\n                print(f\"Mandatory Skills Similarity: {mandatory_skills_similarity:.2f}\")\n                print(f\"Good-to-Have Skills Similarity: {good_to_have_skills_similarity:.2f}\")\n                \n                if expertise_level_similarity is not None:\n                    # Print the expertise level similarity\n                    print(f\"Expertise Level Similarity: {expertise_level_similarity:.2f}\")\n                    \n                    # Sum up the similarities for all aspects\n                    combined_similarity = mandatory_skills_similarity + good_to_have_skills_similarity + expertise_level_similarity\n                    # Print the combined similarity\n                    print(f\"Combined Similarity: {combined_similarity:.2f}\")\n                else:\n                    print(\"Expertise level similarity not considered.\")\n                    \n                print()  # Add a newline for clarity\n            else:\n                print(f\"User Profile {i+1} vs. Project {j+1}:\")\n                print(\"Skills similarity below threshold, expertise level similarity not considered.\")\n                print()\n        else:\n            print(f\"User Profile {i+1} vs. Project {j+1}:\")\n            print(\"Contributor types do not match, skipping other similarities.\")\n            print()\n# Define a custom JSON encoder to handle non-serializable types\nclass CustomJSONEncoder(json.JSONEncoder):\n    def default(self, obj):\n        if isinstance(obj, np.ndarray):\n            return obj.tolist()  # Convert NumPy arrays to Python lists\n        return super().default(obj)\n\n# Initialize a list to store the results\nresults = []\n\n# Iterate through user profiles and project descriptions\nfor i, user_profile in enumerate(user_profiles):\n    for j, project_description in enumerate(project_descriptions):\n        # Check if the contributor types match\n        if user_profile['contributor_type'] == project_description['contributor_type']:\n            # ... (your similarity calculations)\n\n            # Convert NumPy arrays to Python lists within the result dictionary\n            for key, value in result.items():\n                if isinstance(value, np.ndarray):\n                    result[key] = value.tolist()\n                elif isinstance(value, np.float32):\n                    result[key] = float(value)  # Convert np.float32 to native Python float\n\n            # Append the result to the list\n            results.append(result)\n\n# Save the results to a JSON file using the custom JSON encoder\nwith open('similarities1.json', 'w') as json_file:\n    json.dump(results, json_file, indent=4, cls=CustomJSONEncoder)\n","metadata":{"execution":{"iopub.status.busy":"2023-10-01T14:15:55.732298Z","iopub.execute_input":"2023-10-01T14:15:55.732719Z","iopub.status.idle":"2023-10-01T14:15:55.761716Z","shell.execute_reply.started":"2023-10-01T14:15:55.732688Z","shell.execute_reply":"2023-10-01T14:15:55.760944Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"User Profile 1 vs. Project 1:\nMandatory Skills Similarity: 0.87\nGood-to-Have Skills Similarity: 0.07\nExpertise Level Similarity: 0.95\nCombined Similarity: 1.89\n\nUser Profile 1 vs. Project 2:\nContributor types do not match, skipping other similarities.\n\nUser Profile 1 vs. Project 3:\nContributor types do not match, skipping other similarities.\n\nUser Profile 2 vs. Project 1:\nContributor types do not match, skipping other similarities.\n\nUser Profile 2 vs. Project 2:\nSkills similarity below threshold, expertise level similarity not considered.\n\nUser Profile 2 vs. Project 3:\nContributor types do not match, skipping other similarities.\n\nUser Profile 3 vs. Project 1:\nContributor types do not match, skipping other similarities.\n\nUser Profile 3 vs. Project 2:\nContributor types do not match, skipping other similarities.\n\nUser Profile 3 vs. Project 3:\nMandatory Skills Similarity: -0.11\nGood-to-Have Skills Similarity: 0.51\nExpertise Level Similarity: 0.98\nCombined Similarity: 1.37\n\n","output_type":"stream"}]}]}